{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "dptqy3gHYMpW",
    "outputId": "47cfd14d-5d54-4f9f-e1e9-0cfaf9a675c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10379.16s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: openfermion in ./anaconda3/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: sparse in ./anaconda3/lib/python3.12/site-packages (0.15.4)\n",
      "Requirement already satisfied: cirq-core~=1.0 in ./anaconda3/lib/python3.12/site-packages (from openfermion) (1.4.1)\n",
      "Requirement already satisfied: deprecation in ./anaconda3/lib/python3.12/site-packages (from openfermion) (2.1.0)\n",
      "Requirement already satisfied: h5py>=2.8 in ./anaconda3/lib/python3.12/site-packages (from openfermion) (3.11.0)\n",
      "Requirement already satisfied: networkx in ./anaconda3/lib/python3.12/site-packages (from openfermion) (3.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in ./anaconda3/lib/python3.12/site-packages (from openfermion) (1.26.4)\n",
      "Requirement already satisfied: pubchempy in ./anaconda3/lib/python3.12/site-packages (from openfermion) (1.0.4)\n",
      "Requirement already satisfied: requests>=2.18 in ./anaconda3/lib/python3.12/site-packages (from openfermion) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./anaconda3/lib/python3.12/site-packages (from openfermion) (1.13.1)\n",
      "Requirement already satisfied: sympy in ./anaconda3/lib/python3.12/site-packages (from openfermion) (1.13.2)\n",
      "Requirement already satisfied: numba>=0.49 in ./anaconda3/lib/python3.12/site-packages (from sparse) (0.60.0)\n",
      "Requirement already satisfied: attrs>=21.3.0 in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (23.1.0)\n",
      "Requirement already satisfied: duet>=0.2.8 in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (0.2.9)\n",
      "Requirement already satisfied: matplotlib~=3.0 in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (3.9.2)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (2.2.2)\n",
      "Requirement already satisfied: sortedcontainers~=2.0 in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (4.11.0)\n",
      "Requirement already satisfied: tqdm in ./anaconda3/lib/python3.12/site-packages (from cirq-core~=1.0->openfermion) (4.66.5)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in ./anaconda3/lib/python3.12/site-packages (from numba>=0.49->sparse) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.12/site-packages (from requests>=2.18->openfermion) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.12/site-packages (from requests>=2.18->openfermion) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./anaconda3/lib/python3.12/site-packages (from requests>=2.18->openfermion) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.12/site-packages (from requests>=2.18->openfermion) (2024.8.30)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.12/site-packages (from deprecation->openfermion) (24.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./anaconda3/lib/python3.12/site-packages (from sympy->openfermion) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./anaconda3/lib/python3.12/site-packages (from matplotlib~=3.0->cirq-core~=1.0->openfermion) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.12/site-packages (from pandas->cirq-core~=1.0->openfermion) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./anaconda3/lib/python3.12/site-packages (from pandas->cirq-core~=1.0->openfermion) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->cirq-core~=1.0->openfermion) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openfermion sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSn64bM4YmzX"
   },
   "source": [
    "### Código base de OpenFermion, hay mucho al pedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D12tQ4uXYYxp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openfermion as of\n",
    "from tqdm import tqdm\n",
    "from itertools import combinations\n",
    "from openfermion.utils import commutator, count_qubits, hermitian_conjugated\n",
    "import functools\n",
    "import concurrent.futures\n",
    "from numba import njit\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import sparse\n",
    "import itertools\n",
    "\n",
    "# Generación de base\n",
    "class fixed_basis:\n",
    "    @staticmethod\n",
    "    def int_to_bin(k, d):\n",
    "        return np.base_repr(k, 2).zfill(d)\n",
    "\n",
    "    @staticmethod\n",
    "    def bin_to_op(b):\n",
    "        tups = [(i, 1) for i, k in list(enumerate(list(b))) if k == '1']\n",
    "        return of.FermionOperator(tups)\n",
    "\n",
    "    def idx_to_repr(self, idx):\n",
    "        return self.canonicals[idx]\n",
    "\n",
    "    def opr_to_idx(self, opr):\n",
    "        for i in range(self.size): # Evitar esto ordenando opr\n",
    "            if self.base[i] == opr:\n",
    "                return i\n",
    "\n",
    "    # Calcula el valor medio a partir del indice del vector y el operador\n",
    "    def idx_mean_val(self, idx: int, op: of.FermionOperator):\n",
    "        vec = self.idx_to_repr(idx)\n",
    "        return np.real(np.transpose(vec) @ of.get_sparse_operator(op, n_qubits=self.d) @ vec)\n",
    "\n",
    "    # Calcula el valor medio a partir de un estado y el operador\n",
    "    def mean_val(self, vec, op):\n",
    "        idx = self.opr_to_idx(vec)\n",
    "        return self.idx_mean_val(idx, op)\n",
    "\n",
    "    # Calcula la contracción de un operador sobre dos estados dados\n",
    "    def idx_contraction(self, idx_1, idx_2, op):\n",
    "        rep = lambda x: self.idx_to_repr(x)\n",
    "        return np.real(np.transpose(rep(idx_1)) @ of.get_sparse_operator(op, n_qubits=self.d) @ rep(idx_2))\n",
    "\n",
    "    def create_basis(self, d, num = None, pairs = False):\n",
    "        basis = []\n",
    "        num_ele = []\n",
    "        for k in range(0,2**d):\n",
    "            b = self.int_to_bin(k, d)\n",
    "            if num != None:\n",
    "                if b.count('1') == num:\n",
    "                    if pairs:\n",
    "                        if np.all(b[::2] == b[1::2]):\n",
    "                            oper = self.bin_to_op(b)\n",
    "                            basis.append(oper)\n",
    "                            num_ele.append(k)\n",
    "                    else:\n",
    "                        oper = self.bin_to_op(b)\n",
    "                        basis.append(oper)\n",
    "                        num_ele.append(k)\n",
    "            else:\n",
    "                oper = self.bin_to_op(b)\n",
    "                basis.append(oper)\n",
    "        return basis, num_ele\n",
    "\n",
    "    def __init__(self, d, num = None, pairs = False):\n",
    "        self.d = d\n",
    "        self.num = num\n",
    "        self.m = num\n",
    "        self.base, self.num_ele = self.create_basis(d, num, pairs)\n",
    "        self.size = len(self.base)\n",
    "        self.canonicals = np.eye(self.size)\n",
    "        self.pairs = pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def cdc(i, j):\n",
    "        return of.FermionOperator(((i,1),(j,0)))\n",
    "\n",
    "    @staticmethod\n",
    "    def cc(i, j):\n",
    "        return of.FermionOperator(((i,0),(j,0)))\n",
    "\n",
    "    # Del indice, cuenta el número de partículas\n",
    "    def num_idx(self, idx):\n",
    "        b = self.int_to_bin(idx, basis.d)\n",
    "        return b.count('1')\n",
    "\n",
    "    # Calculo de rho1 (via directa, lento, y solo definido en la base por ahora)\n",
    "    def rho_1(self, op):\n",
    "        # Necesitamos un índice, es?\n",
    "        if type(op) != int:\n",
    "            op = self.opr_to_idx(op)\n",
    "        mat = np.zeros((self.d, self.d))\n",
    "        for i in range(self.d):\n",
    "            for j in range(self.d):\n",
    "                cdc = self.cdc(j, i)\n",
    "                mat[i,j] = self.idx_mean_val(op, cdc)\n",
    "        return mat\n",
    "\n",
    "# Calculo de generadores de rho1\n",
    "def rho_1_gen(basis):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    indices = []\n",
    "    values = []\n",
    "    shape = (basis.d, basis.d, basis.size, basis.size)\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d)):\n",
    "        for j in range(0, d):\n",
    "            # Generamos el operador\n",
    "            op = basis.cdc(j, i)\n",
    "            print(op)\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "# Calculo de rho1 (via generadores) de un vector en la base canonica\n",
    "def rho_1(vect, rho_1_arrays):\n",
    "    if len(vect.shape) == 1: # vectores\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_1_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_1_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_1_arrays)\n",
    "\n",
    "# Calculo de indices de rho2kkbar\n",
    "def get_kkbar_indices(t_basis):\n",
    "    indices = []\n",
    "    for i, ind in enumerate(t_basis.num_ele):\n",
    "        v = t_basis.int_to_bin(ind, t_basis.d)\n",
    "        if np.all(v[::2] == v[1::2]):\n",
    "            indices.append(i)\n",
    "    return indices\n",
    "\n",
    "# Calculo de generadores de rho2\n",
    "def rho_2_gen(basis, t_basis, idx_list = []):\n",
    "    # Vamos a crear un hipersparse de TF, almacenamos los valores acá\n",
    "    indices = []\n",
    "    values = []\n",
    "    if len(idx_list) == basis.m:\n",
    "        idx_list = idx_list\n",
    "    elif len(idx_list) == basis.m**4:\n",
    "        idx_list = np.unique(idx_list[:,0])\n",
    "    else:\n",
    "        idx_list = range(t_basis.size)\n",
    "    shape = (len(idx_list), len(idx_list), basis.size, basis.size)\n",
    "    for i, ii in tqdm(enumerate(idx_list), total=len(idx_list)):\n",
    "        for j, jj in enumerate(idx_list):\n",
    "            # Generamos el operador\n",
    "            op = t_basis.base[jj]*of.utils.hermitian_conjugated(t_basis.base[ii])\n",
    "            if basis.num == None:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))\n",
    "            else:\n",
    "                mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "def rho_m_gen(basis, m):\n",
    "    indices = []\n",
    "    values = []\n",
    "    m_basis = fixed_basis(basis.d, num=m, pairs=basis.pairs)\n",
    "    shape = (m_basis.size, m_basis.size, basis.size, basis.size)\n",
    "    \n",
    "    it_set = np.arange(m_basis.size)[::-1]\n",
    "    for i, ii in tqdm(enumerate(it_set), total=m_basis.size):\n",
    "        for j, jj in enumerate(it_set):\n",
    "            # Generamos el operador\n",
    "            op = m_basis.base[jj]*of.utils.hermitian_conjugated(m_basis.base[ii])\n",
    "            mat = np.real(of.get_sparse_operator(op, n_qubits=basis.d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extraemos la información\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([i, j, r, c])\n",
    "                values.append(v)\n",
    "\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n",
    "\n",
    "def rho_m(vect, rho_m_arrays):\n",
    "    return sparse.einsum('k,ijkl,l->ij', vect, rho_m_arrays, vect)\n",
    "\n",
    "# Calculo de rho2 (via generadores) de un estado en la base canonica\n",
    "def rho_2(vect, rho_2_arrays):\n",
    "    if len(vect.shape) == 1: # vectores SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('k,ijkl,l->ij', vect, rho_2_arrays, vect)\n",
    "    elif len(vect.shape) == 2: # mat densidad SOLO RHO2 COMPLETA\n",
    "        return sparse.einsum('ijkl,kl->ij', rho_2_arrays, vect)\n",
    "    else: # mat densidad batcheadas\n",
    "        return sparse.einsum('bkl,ijkl->bij', vect, rho_2_arrays)\n",
    "\n",
    "# Calculo de generadores de K (usado para quasiparticles) WIP SPARSE\n",
    "def k_gen(basis):\n",
    "    mat = np.zeros((basis.d, basis.d, basis.size, basis.size))\n",
    "    d = basis.d\n",
    "    for i in tqdm(range(0, d), total=d):\n",
    "        for j in range(0, d):\n",
    "            op = basis.cc(j, i)\n",
    "            if basis.num == None:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()\n",
    "            else:\n",
    "                mat[i,j,::] = np.real(of.get_sparse_operator(op, n_qubits=d)).todense()[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "    return mat\n",
    "\n",
    "def k_vect(vect, k_gen):\n",
    "    return np.einsum('k,ijkl,l->ij', vect, k_gen, vect)\n",
    "\n",
    "# Calculo la matrix rho de cuasipartículas  WIP SPARSE\n",
    "def rho_qsp(vect, rho_1_arrays, k_arrays, rho1 = None):\n",
    "    if type(rho1) == None:\n",
    "        rho1 = rho_1(vect, rho_1_arrays)\n",
    "    k = k_vect(vect, k_arrays)\n",
    "\n",
    "    mat = np.block([[rho1, k], [-np.conjugate(k), np.eye(rho_1_arrays.shape[0])-np.conjugate(rho1)]])\n",
    "    return mat\n",
    "\n",
    "# Devuelve los indices que tienen a level ocupado\n",
    "def level_proy(d, level):\n",
    "    ids = []\n",
    "    for k in range(0,2**d):\n",
    "        b = fixed_basis.int_to_bin(k, d)\n",
    "        if b[level] == '1':\n",
    "            ids.append(k)\n",
    "    arr = np.zeros(2**d)\n",
    "    arr[np.array(ids)] = 1\n",
    "    return arr, ids\n",
    "\n",
    "def parity_levels(d):\n",
    "    rng = range(2**d)\n",
    "    binary_repr = np.vectorize(np.binary_repr)(rng)\n",
    "    ones_c = np.char.count(binary_repr, '1')\n",
    "    return np.array(rng)[ones_c % 2 == 1] # seleccionamos estados impares\n",
    "\n",
    "# Devuelve el vector postmedido\n",
    "def measure(basis, vect, level = 1):\n",
    "    l_arr, l_ids = level_proy(basis.d, level)\n",
    "    proy_v = vect * l_arr\n",
    "    comp_arr = np.logical_not(l_arr).astype(int)\n",
    "    comp_v = vect * comp_arr\n",
    "    norm = lambda v: v / np.linalg.norm(v)\n",
    "    return norm(proy_v), norm(comp_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biARZcbkatm9"
   },
   "source": [
    "### Hamiltoniano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "jy6UOPwPa2U1"
   },
   "outputs": [],
   "source": [
    "def two_body_hamiltonian_sp(energy_seed, G_batched, rho_1_arrays, rho_2_arrays, h_type = None, indices = None):\n",
    "    # SECCIÓN ENERGIAS\n",
    "    ## Dado un seed de niveles diagonal construimos la mat simétrica dxd que multiplicara a c^dag_i c_j\n",
    "    diagonal = np.zeros((gpu_batch_size, basis.d, basis.d))\n",
    "    diagonal[:, np.arange(basis.d), np.arange(basis.d)] = energy_seed\n",
    "    ## Convertimos en sparse la energia y la expandimos\n",
    "    energy_matrix = sparse.COO.from_numpy(diagonal)\n",
    "    energy_matrix_expanded = energy_matrix[:, :, :, np.newaxis, np.newaxis]\n",
    "    rho_1_gen_transposed = rho_1_arrays.transpose(axes=[1, 0, 2, 3])\n",
    "    # Multiplicamos por los operadores C^dag C\n",
    "    matprod = energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:]\n",
    "    h0_arr = matprod.sum(axis=[1,2])\n",
    "\n",
    "    # SECCIÓN INTERACCIÓN\n",
    "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
    "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
    "\n",
    "    # Creamos la mat de t_basis, nada más que hacer! los coeficientes están dados. Bueno, y simetrizar\n",
    "    i_shape = basis.m**2 if h_type == 'blockgen' else t_basis.size\n",
    "    int_mat = np.zeros((gpu_batch_size, i_shape, i_shape))\n",
    "\n",
    "    # Si nos dieron indices, debemos llevar el G_arr (d,d) -> (t_basis.size, t_basis.size)\n",
    "    ## Caso kkbar (el único con índices)\n",
    "    if indices != None and len(indices) == basis.m:\n",
    "        indices = np.array(indices)\n",
    "        int_mat[:, indices[:, None], indices[None, :]] = G_batched\n",
    "    elif h_type == 'randomenerg' or h_type == 'blockgen':\n",
    "        idx = np.triu_indices(i_shape)\n",
    "        int_mat[:, idx[0], idx[1]] = G_batched\n",
    "    else:\n",
    "        raise ValueError\n",
    "    diagonal = np.einsum('ijk,ijk->ijk', int_mat, np.eye(i_shape)[np.newaxis,::])\n",
    "    int_mat = int_mat + np.transpose(int_mat, axes=(0,2,1)) - diagonal\n",
    "    int_mat = sparse.COO.from_numpy(int_mat)\n",
    "\n",
    "    # Preparamos las dimensiones y multiplicamos\n",
    "    int_mat_expanded = int_mat[:, :, :, np.newaxis, np.newaxis]\n",
    "    rho_2_gen_transposed = rho_2_arrays.transpose(axes=[1, 0, 2, 3])\n",
    "    matprod = int_mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:]\n",
    "    hi_arr = matprod.sum(axis=[1,2])\n",
    "\n",
    "    return h0_arr - hi_arr\n",
    "\n",
    "\n",
    "def state_energy(state, h_arr):\n",
    "    return tf.linalg.trace(tf.matmul(state, h_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KEdgbpKSbAiZ"
   },
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import sparse\n",
    "import openfermion as of\n",
    "\n",
    "\n",
    "def process_rho_m_chunk(args):\n",
    "    \"\"\"Process a subset of the outer loop for rho_m_gen.\"\"\"\n",
    "    chunk, m_basis, basis, d = args\n",
    "    indices = []\n",
    "    values = []\n",
    "    rv = lambda x: m_basis.size-x-1 # invertimos la indexación tq [0,0] = 0^0\n",
    "    \n",
    "    for ii in chunk:\n",
    "        for jj in range(m_basis.size):\n",
    "            # Generate the operator\n",
    "            op = m_basis.base[jj] * of.utils.hermitian_conjugated(m_basis.base[ii])\n",
    "            mat = np.real(of.get_sparse_operator(op, n_qubits=d))[np.ix_(basis.num_ele, basis.num_ele)]\n",
    "            # Extract the information\n",
    "            n_r, n_c = mat.nonzero()\n",
    "            data = mat.data\n",
    "            for r, c, v in zip(n_r, n_c, data):\n",
    "                indices.append([rv(ii), rv(jj), r, c])\n",
    "                values.append(v)\n",
    "\n",
    "    return indices, values\n",
    "\n",
    "\n",
    "def rho_m_gen(basis, m, num_workers=16):\n",
    "    \"\"\"Parallel version of rho_m_gen.\"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "    m_basis = fixed_basis(basis.d, num=m, pairs=basis.pairs)\n",
    "    shape = (m_basis.size, m_basis.size, basis.size, basis.size)\n",
    "\n",
    "    # Split the workload into chunks\n",
    "    chunks = np.array_split(range(m_basis.size), num_workers)\n",
    "    args = [(chunk, m_basis, basis, basis.d) for chunk in chunks]\n",
    "\n",
    "    # Use multiprocessing\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(tqdm(executor.map(process_rho_m_chunk, args), total=num_workers))\n",
    "\n",
    "    # Combine results from all workers\n",
    "    for indices_chunk, values_chunk in results:\n",
    "        indices.extend(indices_chunk)\n",
    "        values.extend(values_chunk)\n",
    "\n",
    "    indices_t = np.array(indices).T\n",
    "    s_t = sparse.COO(indices_t, values, shape=shape)\n",
    "    return s_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bM1C0Y31bAEo",
    "outputId": "1fc64471-fec6-4ad3-eb13-ef5037d51b41"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 14.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.26it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:04<00:00,  3.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 20.74it/s]\n"
     ]
    }
   ],
   "source": [
    "#### INIT ####\n",
    "d = 8\n",
    "num = d//2 # En caso de ser None, es GC\n",
    "pairs = False\n",
    "\n",
    "# Bases\n",
    "basis = fixed_basis(d, num=num, pairs=pairs)\n",
    "t_basis = fixed_basis(d, num=2, pairs=pairs)\n",
    "# Arrays\n",
    "rho_1_arrays = rho_m_gen(basis, 1)\n",
    "rho_2_arrays = rho_m_gen(basis, 2)\n",
    "rho_arrays = rho_m_gen(basis, 2)\n",
    "# Indices\n",
    "k_indices = get_kkbar_indices(t_basis)\n",
    "# Arrays reducidos\n",
    "rho_2_kkbar_arrays = rho_2_gen(basis, t_basis, idx_list = k_indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wnTTFNxMdFhv",
    "outputId": "003b7d0d-789a-45f7-cdfb-45a803e9efd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m g_range:\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(g)\n\u001b[0;32m---> 19\u001b[0m     rho_range[g] \u001b[38;5;241m=\u001b[39m compute_g(g)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Ploteamos\u001b[39;00m\n\u001b[1;32m     22\u001b[0m rho_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(rho_range)\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mcompute_g\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m      4\u001b[0m energy_seed \u001b[38;5;241m=\u001b[39m en_batch\n\u001b[1;32m      5\u001b[0m G_batched \u001b[38;5;241m=\u001b[39m [g \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mones((basis\u001b[38;5;241m.\u001b[39mm,basis\u001b[38;5;241m.\u001b[39mm)) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m----> 6\u001b[0m h \u001b[38;5;241m=\u001b[39m two_body_hamiltonian_sp(energy_seed, G_batched, rho_1_arrays, rho_2_arrays, h_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m, indices \u001b[38;5;241m=\u001b[39m k_indices)\n\u001b[1;32m      7\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mtodense()\n\u001b[1;32m      8\u001b[0m fund \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(h[\u001b[38;5;241m0\u001b[39m,:,:])[\u001b[38;5;241m1\u001b[39m][:,\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mtwo_body_hamiltonian_sp\u001b[0;34m(energy_seed, G_batched, rho_1_arrays, rho_2_arrays, h_type, indices)\u001b[0m\n\u001b[1;32m     29\u001b[0m     int_mat[:, idx[\u001b[38;5;241m0\u001b[39m], idx[\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m G_batched\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m     32\u001b[0m diagonal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mijk,ijk->ijk\u001b[39m\u001b[38;5;124m'\u001b[39m, int_mat, np\u001b[38;5;241m.\u001b[39meye(i_shape)[np\u001b[38;5;241m.\u001b[39mnewaxis,::])\n\u001b[1;32m     33\u001b[0m int_mat \u001b[38;5;241m=\u001b[39m int_mat \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(int_mat, axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m-\u001b[39m diagonal\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hamiltoniano\n",
    "def compute_g(g):\n",
    "    en_batch = [np.repeat(np.arange(0, basis.num) - basis.num//2 + 1/2, 2) for _ in range(0,1)] # Semilla para H equiespaciado\n",
    "    energy_seed = en_batch\n",
    "    G_batched = [g * np.ones((basis.m,basis.m)) for _ in range(0, 1)]\n",
    "    h = two_body_hamiltonian_sp(energy_seed, G_batched, rho_1_arrays, rho_2_arrays, h_type = 'const', indices = k_indices)\n",
    "    h = h.todense()\n",
    "    fund = np.linalg.eigh(h[0,:,:])[1][:,0]\n",
    "    rho = rho_m(fund, rho_2_arrays)\n",
    "    r = np.sort(np.linalg.eigvals(rho.todense()).real)\n",
    "    print(r)\n",
    "    return (g, r)\n",
    "\n",
    "rho_range = {}\n",
    "g_range = np.linspace(0,5,10)\n",
    "gpu_batch_size = 1\n",
    "for g in g_range:\n",
    "    print(g)\n",
    "    rho_range[g] = compute_g(g)\n",
    "\n",
    "# Ploteamos\n",
    "rho_range = dict(rho_range)\n",
    "rho_range = dict(sorted(rho_range.items()))\n",
    "x_axis = list(g_range)\n",
    "values = list(rho_range.items())\n",
    "size = len(values[0][1])\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "num = 10\n",
    "# Plot using matplotlib\n",
    "# Use LaTeX to format all text\n",
    "\n",
    "plt.rcParams['text.usetex'] = False #True\n",
    "plt.rcParams['axes.labelsize'] = 30\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "\n",
    "plt.cla()\n",
    "plt.figure(figsize=(8, 5))\n",
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "for k in range(1,size):\n",
    "    plt.plot(x_axis, [values[j][1][k] for j in range(0,num)], linewidth=2)\n",
    "\n",
    "#plt.xlabel(r'$G/\\epsilon$', fontsize=18)\n",
    "#plt.ylabel(r'$\\lambda^{(2)}$', fontsize=18)\n",
    "#plt.xlim(0, 5)  # Set x-axis limits from 0 to 6\n",
    "#plt.ylim(0, 5)  # Set y-axis limits from 5 to 12\n",
    "\n",
    "#matplotlib.use('Agg')\n",
    "#matplotlib.use('GTK3Agg')\n",
    "\n",
    "plt.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True)\n",
    "\n",
    "# Enable minor ticks on the x-axis\n",
    "plt.minorticks_on()\n",
    "\n",
    "# Customize the appearance of minor ticks on the x-axis\n",
    "plt.tick_params(axis='x', which='minor', width=1.5)\n",
    "plt.tick_params(axis='x', which='major', width=1.5)\n",
    "plt.tick_params(axis='y', which='major', width=1.5)\n",
    "\n",
    "plt.show()\n",
    "#matplotlib.pyplot.savefig('filename.png')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPucTBntS2jkyL8KkQNRnh4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
